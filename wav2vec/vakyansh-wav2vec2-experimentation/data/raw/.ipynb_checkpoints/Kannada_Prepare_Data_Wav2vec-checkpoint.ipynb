{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Conversion Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Converter = {\n",
    "#     \" \" : \"SIL\", #NOT SURE\n",
    "    \"0C80\" : \"\",\n",
    "    \"0C81\" : \"\",\n",
    "    \"0C82\" : \"q\",\n",
    "    \"0C83\" : \"hq\",\n",
    "    \"0C84\" : \"\",\n",
    "    \"0C85\" : \"a\",\n",
    "    \"0C86\" : \"aa\",\n",
    "    \"0C87\" : \"i\",\n",
    "    \"0C88\" : \"ii\",\n",
    "    \"0C89\" : \"u\",\n",
    "    \"0C8A\" : \"uu\",\n",
    "    \"0C8B\" : \"rq\",\n",
    "    \"0C8C\" : \"\",\n",
    "    \"0C8D\" : \"\",####Reserved\n",
    "    \"0C8E\" : \"e\",\n",
    "    \"0C8F\" : \"ee\",\n",
    "    \"0C90\" : \"ai\",\n",
    "    \"0C91\" : \"\",####Reserved\n",
    "    \"0C92\" : \"o\",\n",
    "    \"0C93\" : \"oo\",\n",
    "    \"0C94\" : \"au\",\n",
    "    \"0C95\" : \"k\",\n",
    "    \"0C96\" : \"kh\",\n",
    "    \"0C97\" : \"g\",\n",
    "    \"0C98\" : \"gh\",\n",
    "    \"0C99\" : \"ng\",\n",
    "    \"0C9A\" : \"c\",\n",
    "    \"0C9B\" : \"ch\",\n",
    "    \"0C9C\" : \"j\",\n",
    "    \"0C9D\" : \"jh\",\n",
    "    \"0C9E\" : \"nj\",\n",
    "    \"0C9F\" : \"tx\",\n",
    "    \"0CA0\" : \"txh\",\n",
    "    \"0CA1\" : \"dx\",\n",
    "    \"0CA2\" : \"dxh\",\n",
    "    \"0CA3\" : \"nx\",\n",
    "    \"0CA4\" : \"t\",\n",
    "    \"0CA5\" : \"th\",\n",
    "    \"0CA6\" : \"d\",\n",
    "    \"0CA7\" : \"dh\",\n",
    "    \"0CA8\" : \"n\",\n",
    "    \"0CA9\" : \"\",####Reserved\n",
    "    \"0CAA\" : \"p\",\n",
    "    \"0CAB\" : \"ph\",\n",
    "    \"0CAC\" : \"b\",\n",
    "    \"0CAD\" : \"bh\",\n",
    "    \"0CAE\" : \"m\",\n",
    "    \"0CAF\" : \"y\",\n",
    "    \"0CB0\" : \"r\",\n",
    "    \"0CB1\" : \"rx\",\n",
    "    \"0CB2\" : \"l\",\n",
    "    \"0CB3\" : \"lx\",\n",
    "    \"0CB4\" : \"\",####Reserved\n",
    "    \"0CB5\" : \"w\",\n",
    "    \"0CB6\" : \"sh\",\n",
    "    \"0CB7\" : \"sx\",\n",
    "    \"0CB8\" : \"s\",\n",
    "    \"0CB9\" : \"h\",\n",
    "    \"0CBA\" : \"\",\n",
    "    \"0CBB\" : \"\",\n",
    "    \"0CBC\" : \"\",\n",
    "    \"0CBD\" : \"\",\n",
    "    \"0CBE\" : \"aa\",\n",
    "    \"0CBF\" : \"i\",\n",
    "    \"0CC0\" : \"ii\",\n",
    "    \"0CC1\" : \"u\",\n",
    "    \"0CC2\" : \"uu\",\n",
    "    \"0CC3\" : \"rq\",\n",
    "    \"0CC4\" : \"rq\",\n",
    "    \"0CC5\" : \"\",####Reserved\n",
    "    \"0CC6\" : \"e\",\n",
    "    \"0CC7\" : \"ee\",\n",
    "    \"0CC8\" : \"ai\",\n",
    "    \"0CC9\" : \"\",####Reserved\n",
    "    \"0CCA\" : \"o\",\n",
    "    \"0CCB\" : \"oo\",\n",
    "    \"0CCC\" : \"au\",\n",
    "    \"0CCD\" : \"eu\",\n",
    "    \"0CCE\" : \"\",\n",
    "    \"0CCF\" : \"\",\n",
    "    \"0CD0\" : \"\",\n",
    "    \"0CD1\" : \"\",\n",
    "    \"0CD2\" : \"\",\n",
    "    \"0CD3\" : \"\",\n",
    "    \"0CD4\" : \"\",\n",
    "    \"0CD5\" : \"\",\n",
    "    \"0CD6\" : \"\",\n",
    "    \"0CD7\" : \"\",\n",
    "    \"0CD8\" : \"\",\n",
    "    \"0CD9\" : \"\",\n",
    "    \"0CDA\" : \"\",\n",
    "    \"0CDB\" : \"\",\n",
    "    \"0CDC\" : \"\",\n",
    "    \"0CDD\" : \"\",\n",
    "    \"0CDE\" : \"\",\n",
    "    \"0CDF\" : \"\",\n",
    "    \"0CE0\" : \"\",\n",
    "    \"0CE1\" : \"\",\n",
    "    \"0CE2\" : \"\",\n",
    "    \"0CE3\" : \"\",\n",
    "    \"0CE4\" : \"\",####Reserved\n",
    "    \"0CE5\" : \"\",####Reserved\n",
    "    \"0CE6\" : \"\",\n",
    "    \"0CE7\" : \"\",\n",
    "    \"0CE8\" : \"\",\n",
    "    \"0CE9\" : \"\",\n",
    "    \"0CEA\" : \"\",\n",
    "    \"0CEB\" : \"\",\n",
    "    \"0CEC\" : \"\",\n",
    "    \"0CED\" : \"\",\n",
    "    \"0CEE\" : \"\",\n",
    "    \"0CEF\" : \"\",\n",
    "    \"0CF0\" : \"\",\n",
    "    \"0CF1\" : \"\",\n",
    "    \"0CF2\" : \"\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc = '''!()-[‘’]{`};:'\",\\, <>../?@#$%^&*_~'''\n",
    "alphabets = 'letter-en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_str = \"ಸಂಬಂಧ. ಬ‘ಳ’ಸಿಕೊಂಡಿದೆ. ಅಂಕಿ, ಗೊತ್ತುಮಾಡುತ್ತದೆ.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ele in test_str:  \n",
    "    if ele in punc:  \n",
    "        test_str = test_str.replace(ele, \"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ಸಂಬಂಧಬಳಸಿಕೊಂಡಿದೆಅಂಕಿಗೊತ್ತುಮಾಡುತ್ತದೆ\n"
     ]
    }
   ],
   "source": [
    "print(test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\\\u0cb8\\\\u0c82\\\\u0cac\\\\u0c82\\\\u0ca7\\\\u0cac\\\\u0cb3\\\\u0cb8\\\\u0cbf\\\\u0c95\\\\u0cca\\\\u0c82\\\\u0ca1\\\\u0cbf\\\\u0ca6\\\\u0cc6\\\\u0c85\\\\u0c82\\\\u0c95\\\\u0cbf\\\\u0c97\\\\u0cca\\\\u0ca4\\\\u0ccd\\\\u0ca4\\\\u0cc1\\\\u0cae\\\\u0cbe\\\\u0ca1\\\\u0cc1\\\\u0ca4\\\\u0ccd\\\\u0ca4\\\\u0ca6\\\\u0cc6'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_str.encode('unicode-escape')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create list of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_words = []\n",
    "all_rows = []\n",
    "all_words = []\n",
    "\n",
    "with open('line_index_female.tsv', newline='',encoding='utf-8') as tsvin, open('line_index_female_Punctuation_removed.tsv', 'w', newline='', encoding=\"utf-8\") as tsvoutm:\n",
    "    tsvin = csv.reader(tsvin, delimiter='\\t')\n",
    "    tsvoutm=csv.writer(tsvoutm)\n",
    "    \n",
    "    #Read each row of dataset\n",
    "    for row in tsvin: \n",
    "        variable=row[0]\n",
    "        words = row[1].split()\n",
    "        all_words=[]\n",
    "        \n",
    "        #Loop through words \n",
    "        for word in words:\n",
    "            #Loop through letters\n",
    "            for ele in word:  \n",
    "                \n",
    "                #remove punctuation and eng stuff\n",
    "                if ele in punc:  \n",
    "                    word = test_str.replace(ele, \"\") \n",
    "                if ele in alphabets:\n",
    "                    word = test_str.replace(ele, \"\")\n",
    "                    \n",
    "            #Add new words to dictionary list\n",
    "            if [word] not in list_of_words:\n",
    "                list_of_words = list_of_words + [[word]]\n",
    "                \n",
    "            #Append clean words back to a list\n",
    "            all_words=all_words+[word]\n",
    "            \n",
    "        #Write list of cleaned words to new file\n",
    "        all_rows=all_rows+[[variable+\"\\t\"+\" \".join(all_words)]]\n",
    "    tsvoutm.writerows(all_rows)\n",
    "    \n",
    "    \n",
    "all_rows = []\n",
    "all_words = []\n",
    "\n",
    "with open('line_index_male.tsv', newline='',encoding='utf-8') as tsvin, open('line_index_male_Punctuation_removed.tsv', 'w', newline='', encoding=\"utf-8\") as tsvoutm:\n",
    "    tsvin = csv.reader(tsvin, delimiter='\\t')\n",
    "    tsvoutm=csv.writer(tsvoutm)\n",
    "    \n",
    "    #Read each row of dataset\n",
    "    for row in tsvin: \n",
    "        variable=row[0]\n",
    "        words = row[1].split()\n",
    "        all_words=[]\n",
    "        \n",
    "        #Lossp through words \n",
    "        for word in words:\n",
    "            #Loop through letters\n",
    "            for ele in word:  \n",
    "                \n",
    "                #remove punctuation and eng stuff\n",
    "                if ele in punc:  \n",
    "                    word = test_str.replace(ele, \"\") \n",
    "                if ele in alphabets:\n",
    "                    word = test_str.replace(ele, \"\")\n",
    "                    \n",
    "            #Add new words to dictionary list\n",
    "            if [word] not in list_of_words:\n",
    "                list_of_words = list_of_words + [[word]]\n",
    "                \n",
    "            #Append clean words back to a list\n",
    "            all_words=all_words+[word]\n",
    "            \n",
    "        #Write list of cleaned words to new file\n",
    "        all_rows=all_rows+[[variable+\"\\t\"+\" \".join(all_words)]]\n",
    "    tsvoutm.writerows(all_rows)\n",
    "    \n",
    "    \n",
    "with open('Word_Library.tsv', 'w', newline='', encoding=\"utf-8\") as tsvout:\n",
    "    tsvout = csv.writer(tsvout, delimiter='\\t')\n",
    "    tsvout.writerows(list_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create lexicon translation for List of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with open('Word_Library.tsv', newline='',encoding='utf-8') as tsvin, open('Dictionary.csv', 'w', newline='', encoding=\"utf-8\") as csvout:\n",
    "#     tsvin = csv.reader(tsvin, delimiter='\\t')\n",
    "#     csvout = csv.writer(csvout)\n",
    "    \n",
    "#     for row in tsvin: \n",
    "#         Unicode = str(row[0].encode('unicode-escape')) \n",
    "#         Unicode = Unicode.replace(\"\\\\\\\\\", \" \")\n",
    "#         Unicode = Unicode.replace(\"'\", \"\")\n",
    "#         Unicode = Unicode.replace(\"b \", \"\")\n",
    "#         Unicode = Unicode.replace(\"u\", \"\")\n",
    "#         Unicode = Unicode.split()\n",
    "#         word = \"\"\n",
    "#         for character in Unicode:\n",
    "#             word = word + Converter.get(character[0:4].upper(),\"\") \n",
    "#             if(len(Converter.get(character[0:4].upper(),\"\"))>0):\n",
    "#                 word = word + \" \"\n",
    "#         csvout.writerows([[row[0],word]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a list of lines with numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = \"1234567890IVXCDivxcd೦೧೨೩೪೫೬೭೮೯\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Code to Mark out text with numbers\n",
    "\n",
    "list_of_numbers = []\n",
    "\n",
    "with open('line_index_female_Punctuation_removed.tsv', newline='',encoding='utf-8') as tsvin:\n",
    "    tsvin = csv.reader(tsvin, delimiter='\\t')\n",
    "    \n",
    "    for row_number,row in enumerate(tsvin): \n",
    "        words = row[1].split()\n",
    "        y=0\n",
    "        for word in words:\n",
    "            for ele in word:\n",
    "                if ele in numbers:\n",
    "                    y=1;\n",
    "                    \n",
    "        if(y):\n",
    "            list_of_numbers = list_of_numbers + [[row[1] + \"In Line {}\".format(row_number)]]\n",
    "                    \n",
    "    \n",
    "with open('line_index_male_Punctuation_removed.tsv', newline='',encoding='utf-8') as tsvin:\n",
    "    tsvin = csv.reader(tsvin, delimiter='\\t')\n",
    "    \n",
    "    for row_number,row in enumerate(tsvin): \n",
    "        words = row[1].split()\n",
    "        y=0\n",
    "        for word in words:\n",
    "            for ele in word:\n",
    "                if ele in numbers:\n",
    "                    y=1;\n",
    "                    \n",
    "        if(y):\n",
    "            list_of_numbers = list_of_numbers + [[row[1] + \"In Line {}\".format(row_number)]]\n",
    "\n",
    "with open('Lines_to_be_deleted.txt', 'w', newline='', encoding=\"utf-8\") as txtout:\n",
    "    txtout = csv.writer(txtout, delimiter='\\t')\n",
    "    txtout.writerows(list_of_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to delete recordings with numbers from dataset and transcript "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"kn_in_male_numbers_deleted/\")\n",
    "os.mkdir(\"kn_in_female_numbers_deleted/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Code to Mark out text with numbers\n",
    "\n",
    "list_of_rows = []\n",
    "\n",
    "with open('line_index_female_Punctuation_removed.tsv', newline='',encoding='utf-8') as tsvin:\n",
    "    tsvin = csv.reader(tsvin, delimiter='\\t')\n",
    "    \n",
    "    for row in tsvin:\n",
    "        words = row[1].split()\n",
    "        y=0\n",
    "        for word in words:\n",
    "            for ele in word:\n",
    "                if ele in numbers:\n",
    "                    y=1;\n",
    "\n",
    "        if(y==0):\n",
    "            list_of_rows = list_of_rows + [row]\n",
    "            shutil.copyfile(\"kn_in_female/\"+row[0]+\".wav\", \"kn_in_female_numbers_deleted/\"+row[0]+\".wav\")\n",
    "#         else:\n",
    "#             os.remove(\"kn_in_female_numbers_deleted/\"+row[0]+\".wav\")\n",
    "                    \n",
    "with open('line_index_female_numbers_removed.tsv', 'w', newline='', encoding=\"utf-8\") as tsvout:\n",
    "    tsvout = csv.writer(tsvout, delimiter='\\t')\n",
    "    tsvout.writerows(list_of_rows)           \n",
    "    \n",
    "list_of_rows = []\n",
    "    \n",
    "with open('line_index_male_Punctuation_removed.tsv', newline='',encoding='utf-8') as tsvin:\n",
    "    tsvin = csv.reader(tsvin, delimiter='\\t')\n",
    "    \n",
    "    for row in tsvin:\n",
    "        words = row[1].split()\n",
    "        y=0\n",
    "        for word in words:\n",
    "            for ele in word:\n",
    "                if ele in numbers:\n",
    "                    y=1;\n",
    "\n",
    "        if(y==0):\n",
    "            list_of_rows = list_of_rows + [row]\n",
    "            shutil.copyfile(\"kn_in_male/\"+row[0]+\".wav\", \"kn_in_male_numbers_deleted/\"+row[0]+\".wav\")\n",
    "#         else:\n",
    "#             os.remove(\"kn_in_male_numbers_deleted/\"+row[0]+\".wav\")\n",
    "\n",
    "with open('line_index_male_numbers_removed.tsv', 'w', newline='', encoding=\"utf-8\") as tsvout:\n",
    "    tsvout = csv.writer(tsvout, delimiter='\\t')\n",
    "    tsvout.writerows(list_of_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining all unique phenomes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ಪ', 'ರ', '್', 'ವ', 'ತ', 'ಗ', 'ಳ', 'ು', 'ಾ', 'ಯ', 'ಿ', 'ನ', 'ಣ', 'ಸ', 'ಂ', 'ಬ', 'ಧ', 'ಕ', 'ೊ', 'ಡ', 'ದ', 'ೆ', 'ಅ', 'ಮ', 'ಚ', 'ಲ', 'ಷ', 'ಥ', 'ಇ', 'ೇ', 'ಹ', 'ೋ', 'ೈ', 'ಉ', 'ಜ', 'ಒ', 'ಟ', 'ೂ', 'ಈ', 'ಶ', 'ೀ', 'ಭ', 'ಖ', 'ೌ', 'ೃ', 'ಫ', 'ಎ', 'ಞ', 'ಠ', 'ಆ', 'ಏ', 'ಊ', 'ಓ', '\\u200c', 'ಢ', 'ಃ', 'ಘ', 'ಐ', 'ಋ', 'ಛ', 'ಝ', 'ಔ', 'ಙ', '\\u200d']\n"
     ]
    }
   ],
   "source": [
    "letters = []\n",
    "with open('line_index_female_numbers_removed.tsv', newline='',encoding='utf-8') as tsvin:\n",
    "    tsvin = csv.reader(tsvin, delimiter='\\t')\n",
    "    \n",
    "    \n",
    "    for row_number,row in enumerate(tsvin): \n",
    "        words = row[1].split()\n",
    "        y=0\n",
    "        for word in words:\n",
    "            for ele in word:\n",
    "                if ele not in letters:\n",
    "                    letters += ele\n",
    "                    \n",
    "with open('line_index_male_numbers_removed.tsv', newline='',encoding='utf-8') as tsvin:\n",
    "    tsvin = csv.reader(tsvin, delimiter='\\t')\n",
    "    \n",
    "    \n",
    "    for row_number,row in enumerate(tsvin): \n",
    "        words = row[1].split()\n",
    "        y=0\n",
    "        for word in words:\n",
    "            for ele in word:\n",
    "                if ele not in letters:\n",
    "                    letters += ele\n",
    "                    \n",
    "print(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ಂ', 'ಃ', 'ಅ', 'ಆ', 'ಇ', 'ಈ', 'ಉ', 'ಊ', 'ಋ', 'ಎ', 'ಏ', 'ಐ', 'ಒ', 'ಓ', 'ಔ', 'ಕ', 'ಖ', 'ಗ', 'ಘ', 'ಙ', 'ಚ', 'ಛ', 'ಜ', 'ಝ', 'ಞ', 'ಟ', 'ಠ', 'ಡ', 'ಢ', 'ಣ', 'ತ', 'ಥ', 'ದ', 'ಧ', 'ನ', 'ಪ', 'ಫ', 'ಬ', 'ಭ', 'ಮ', 'ಯ', 'ರ', 'ಱ', 'ಲ', 'ಳ', 'ವ', 'ಶ', 'ಷ', 'ಸ', 'ಹ', 'ಾ', 'ಿ', 'ೀ', 'ು', 'ೂ', 'ೃ', 'ೄ', 'ೆ', 'ೇ', 'ೈ', 'ೊ', 'ೋ', 'ೌ', '್']\n"
     ]
    }
   ],
   "source": [
    "# full_string = []\n",
    "# for i,j in Converter.items():\n",
    "#     if(j!=\"\"):\n",
    "#         full_string+= [chr(int(i,16))]\n",
    "# print(full_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Utterance files wav.scp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewList = []\n",
    "\n",
    "with open('line_index_female.tsv', newline='',encoding='utf-8') as tsvin:\n",
    "    tsvin = csv.reader(tsvin, delimiter='\\t')\n",
    "    for row in tsvin: \n",
    "        utterance_id = row[0]\n",
    "        save_location = \"/home/adithya/kaldi/egs/Kannada_Project/Audio/train/kn_in_female/\" + utterance_id + \".wav\"\n",
    "        NewList = NewList + [[utterance_id,save_location]]\n",
    "        \n",
    "          \n",
    "    \n",
    "with open('line_index_male.tsv', newline='',encoding='utf-8') as tsvin:\n",
    "    tsvin = csv.reader(tsvin, delimiter='\\t')\n",
    "    for row in tsvin: \n",
    "        utterance_id = row[0]\n",
    "        save_location = \"/home/adithya/kaldi/egs/Kannada_Project/Audio/train/kn_in_male/\" + utterance_id + \".wav\"\n",
    "        NewList = NewList + [[utterance_id,save_location]]\n",
    "        \n",
    "with open('wav.txt', 'w', newline='', encoding=\"utf-8\") as txtout:\n",
    "    txtout = csv.writer(txtout, delimiter='\\t')\n",
    "    txtout.writerows(NewList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate utt2spk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewList = []\n",
    "\n",
    "with open('line_index_female.tsv', newline='',encoding='utf-8') as tsvin:\n",
    "    tsvin = csv.reader(tsvin, delimiter='\\t')\n",
    "    for row in tsvin: \n",
    "        utterance_id = row[0]\n",
    "        speaker = \"kn_in_female\"\n",
    "        NewList = NewList + [[utterance_id,speaker]]\n",
    "        \n",
    "          \n",
    "    \n",
    "with open('line_index_male.tsv', newline='',encoding='utf-8') as tsvin:\n",
    "    tsvin = csv.reader(tsvin, delimiter='\\t')\n",
    "    for row in tsvin: \n",
    "        utterance_id = row[0]\n",
    "        speaker = \"kn_in_male\"\n",
    "        NewList = NewList + [[utterance_id,speaker]]\n",
    "        \n",
    "with open('utt2spk.txt', 'w', newline='', encoding=\"utf-8\") as txtout:\n",
    "    txtout = csv.writer(txtout, delimiter='\\t')\n",
    "    txtout.writerows(NewList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Corpus.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewList = []\n",
    "\n",
    "with open('line_index_female.tsv', newline='',encoding='utf-8') as tsvin:\n",
    "    tsvin = csv.reader(tsvin, delimiter='\\t')\n",
    "    for row in tsvin: \n",
    "        line = [row[1]]\n",
    "        NewList = NewList + [line]\n",
    "        \n",
    "          \n",
    "    \n",
    "with open('line_index_male.tsv', newline='',encoding='utf-8') as tsvin:\n",
    "    tsvin = csv.reader(tsvin, delimiter='\\t')\n",
    "    for row in tsvin: \n",
    "        line = [row[1]]\n",
    "        NewList = NewList + [line]\n",
    "        \n",
    "with open('corpus.txt', 'w', newline='', encoding=\"utf-8\") as txtout:\n",
    "    txtout = csv.writer(txtout, delimiter='\\t')\n",
    "    txtout.writerows(NewList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
